{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è PersonaPlex Demo ‚Äî Proof of Concept\n",
    "\n",
    "**Proyecto:** PersonaPlex Callbot (Fase 1)\n",
    "\n",
    "Este notebook prueba PersonaPlex en Google Colab con GPU T4.\n",
    "\n",
    "### Antes de empezar:\n",
    "1. ‚úÖ Acepta la licencia del modelo: [nvidia/personaplex-7b-v1](https://huggingface.co/nvidia/personaplex-7b-v1)\n",
    "2. ‚úÖ Ten tu HuggingFace token listo\n",
    "3. ‚úÖ Aseg√∫rate de estar en Runtime ‚Üí GPU T4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Verificar GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"\\n‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Instalar dependencias del sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update -qq && apt-get install -y -qq libopus-dev > /dev/null 2>&1\n",
    "print(\"‚úÖ libopus-dev instalado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Clonar el repositorio e instalar PersonaPlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/personaplex.git\n",
    "%cd personaplex\n",
    "!pip install -q moshi/.\n",
    "!pip install -q accelerate  # Needed for --cpu-offload\n",
    "print(\"\\n‚úÖ PersonaPlex instalado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Autenticaci√≥n con HuggingFace\n",
    "\n",
    "Ingresa tu token de HuggingFace (necesario para descargar los weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Opci√≥n 1: Ingreso manual\n",
    "hf_token = getpass(\"üîë Ingresa tu HuggingFace Token: \")\n",
    "os.environ[\"HF_TOKEN\"] = hf_token\n",
    "\n",
    "# Verificar\n",
    "print(f\"‚úÖ Token configurado ({len(hf_token)} chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Test Offline ‚Äî Modo Asistente\n",
    "\n",
    "Primer test: usar el audio de prueba incluido con la voz NATF2 (femenina natural).\n",
    "\n",
    "‚ö†Ô∏è Usamos `--cpu-offload` porque el T4 tiene 16GB VRAM y el modelo pesa ~14GB en FP16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python -m moshi.offline \\\n",
    "    --voice-prompt \"NATF2.pt\" \\\n",
    "    --input-wav \"assets/test/input_assistant.wav\" \\\n",
    "    --seed 42424242 \\\n",
    "    --output-wav \"output_assistant.wav\" \\\n",
    "    --output-text \"output_assistant.json\" \\\n",
    "    --cpu-offload\n",
    "\n",
    "print(\"\\n‚úÖ Audio generado: output_assistant.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducir resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display, JSON\n",
    "import json\n",
    "\n",
    "print(\"üéß Audio de entrada (lo que 'escuch√≥' PersonaPlex):\")\n",
    "display(Audio(\"assets/test/input_assistant.wav\"))\n",
    "\n",
    "print(\"\\nüéôÔ∏è Respuesta de PersonaPlex:\")\n",
    "display(Audio(\"output_assistant.wav\"))\n",
    "\n",
    "print(\"\\nüìù Transcripci√≥n de la respuesta:\")\n",
    "with open(\"output_assistant.json\") as f:\n",
    "    transcript = json.load(f)\n",
    "    print(json.dumps(transcript, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Test Offline ‚Äî Modo Customer Service\n",
    "\n",
    "Segundo test: modo servicio al cliente con voz masculina NATM1 y un prompt de rol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python -m moshi.offline \\\n",
    "    --voice-prompt \"NATM1.pt\" \\\n",
    "    --text-prompt \"$(cat assets/test/prompt_service.txt)\" \\\n",
    "    --input-wav \"assets/test/input_service.wav\" \\\n",
    "    --seed 42424242 \\\n",
    "    --output-wav \"output_service.wav\" \\\n",
    "    --output-text \"output_service.json\" \\\n",
    "    --cpu-offload\n",
    "\n",
    "print(\"\\n‚úÖ Audio generado: output_service.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéß Audio de entrada (cliente):\")\n",
    "display(Audio(\"assets/test/input_service.wav\"))\n",
    "\n",
    "print(\"\\nüéôÔ∏è Respuesta de PersonaPlex (agente):\")\n",
    "display(Audio(\"output_service.wav\"))\n",
    "\n",
    "print(\"\\nüìù Transcripci√≥n:\")\n",
    "with open(\"output_service.json\") as f:\n",
    "    transcript = json.load(f)\n",
    "    print(json.dumps(transcript, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Probar diferentes voces\n",
    "\n",
    "Iteramos sobre varias voces para comparar calidad y estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voices_to_test = [\"NATF0\", \"NATF2\", \"NATM0\", \"NATM2\", \"VARF1\", \"VARM1\"]\n",
    "\n",
    "import subprocess, json\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "results = {}\n",
    "\n",
    "for voice in voices_to_test:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üé§ Probando voz: {voice}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    out_wav = f\"output_voice_{voice}.wav\"\n",
    "    out_json = f\"output_voice_{voice}.json\"\n",
    "    \n",
    "    result = subprocess.run([\n",
    "        \"python\", \"-m\", \"moshi.offline\",\n",
    "        \"--voice-prompt\", f\"{voice}.pt\",\n",
    "        \"--input-wav\", \"assets/test/input_assistant.wav\",\n",
    "        \"--seed\", \"42424242\",\n",
    "        \"--output-wav\", out_wav,\n",
    "        \"--output-text\", out_json,\n",
    "        \"--cpu-offload\"\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ {voice} completado\")\n",
    "        display(Audio(out_wav))\n",
    "        \n",
    "        with open(out_json) as f:\n",
    "            transcript = json.load(f)\n",
    "            results[voice] = transcript\n",
    "            print(f\"üìù {json.dumps(transcript, indent=2)[:300]}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error con {voice}: {result.stderr[:200]}\")\n",
    "\n",
    "print(f\"\\n\\nüèÅ Voces probadas: {len(results)}/{len(voices_to_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Probar prompt personalizado (Callbot)\n",
    "\n",
    "Simulamos un escenario de callbot tipo OnBotGo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt personalizado estilo callbot\n",
    "custom_prompt = \"\"\"You work for TechSupport Pro which is a technical support service and your name is Sarah. \\\n",
    "Information: You help customers troubleshoot internet connectivity issues. \\\n",
    "Common solutions: restart router (wait 30 seconds), check cable connections, \\\n",
    "run speed test at speedtest.net. If issue persists, schedule technician visit \\\n",
    "(next available: tomorrow 2-4 PM or Thursday 9-11 AM). \\\n",
    "Service costs: Basic plan $29.99/month, Premium $49.99/month with priority support.\"\"\"\n",
    "\n",
    "# Guardar prompt\n",
    "with open(\"custom_prompt.txt\", \"w\") as f:\n",
    "    f.write(custom_prompt)\n",
    "\n",
    "print(\"Prompt guardado ‚úÖ\")\n",
    "print(f\"\\nüìã Prompt:\\n{custom_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Usar el audio de servicio como input (simula un cliente llamando)\n",
    "!python -m moshi.offline \\\n",
    "    --voice-prompt \"NATF2.pt\" \\\n",
    "    --text-prompt \"$(cat custom_prompt.txt)\" \\\n",
    "    --input-wav \"assets/test/input_service.wav\" \\\n",
    "    --seed 42424242 \\\n",
    "    --output-wav \"output_callbot.wav\" \\\n",
    "    --output-text \"output_callbot.json\" \\\n",
    "    --cpu-offload\n",
    "\n",
    "print(\"\\n‚úÖ Callbot test completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéôÔ∏è Respuesta del callbot:\")\n",
    "display(Audio(\"output_callbot.wav\"))\n",
    "\n",
    "print(\"\\nüìù Transcripci√≥n:\")\n",
    "with open(\"output_callbot.json\") as f:\n",
    "    transcript = json.load(f)\n",
    "    print(json.dumps(transcript, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ M√©tricas de Rendimiento\n",
    "\n",
    "Capturamos tiempos y uso de recursos para evaluar viabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, subprocess\n",
    "\n",
    "print(\"üìä Benchmark: Latencia de generaci√≥n offline\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Medir tiempo de una generaci√≥n\n",
    "start = time.time()\n",
    "result = subprocess.run([\n",
    "    \"python\", \"-m\", \"moshi.offline\",\n",
    "    \"--voice-prompt\", \"NATF2.pt\",\n",
    "    \"--input-wav\", \"assets/test/input_assistant.wav\",\n",
    "    \"--seed\", \"12345\",\n",
    "    \"--output-wav\", \"benchmark_output.wav\",\n",
    "    \"--output-text\", \"benchmark_output.json\",\n",
    "    \"--cpu-offload\"\n",
    "], capture_output=True, text=True)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# Duraci√≥n del audio input\n",
    "import wave\n",
    "with wave.open(\"assets/test/input_assistant.wav\") as w:\n",
    "    input_duration = w.getnframes() / w.getframerate()\n",
    "\n",
    "with wave.open(\"benchmark_output.wav\") as w:\n",
    "    output_duration = w.getnframes() / w.getframerate()\n",
    "\n",
    "print(f\"‚è±Ô∏è  Tiempo total: {elapsed:.1f}s\")\n",
    "print(f\"üéµ Duraci√≥n input: {input_duration:.1f}s\")\n",
    "print(f\"üéµ Duraci√≥n output: {output_duration:.1f}s\")\n",
    "print(f\"‚ö° RTF (Real Time Factor): {elapsed/output_duration:.2f}x\")\n",
    "print(f\"   (< 1.0 = m√°s r√°pido que tiempo real)\")\n",
    "\n",
    "# GPU memory\n",
    "!nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"üìã Resumen para PROJECT.md:\")\n",
    "print(f\"   GPU: T4 16GB + cpu-offload\")\n",
    "print(f\"   RTF: {elapsed/output_duration:.2f}x\")\n",
    "print(f\"   Tiempo gen: {elapsed:.1f}s para {output_duration:.1f}s de audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü (Bonus) Servidor Web Interactivo\n",
    "\n",
    "‚ö†Ô∏è Solo funciona si tienes **micr√≥fono** disponible (Colab con Chrome).\n",
    "\n",
    "Esto levanta el Web UI de PersonaPlex con interacci√≥n en tiempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomenta para probar el servidor interactivo\n",
    "# ‚ö†Ô∏è En Colab free, la sesi√≥n puede morir por timeout\n",
    "# ‚ö†Ô∏è Necesita HTTPS para acceso al micr√≥fono\n",
    "\n",
    "# import subprocess, threading\n",
    "# \n",
    "# def run_server():\n",
    "#     subprocess.run([\n",
    "#         \"python\", \"-m\", \"moshi.server\",\n",
    "#         \"--ssl\", \"/tmp/ssl_certs\",\n",
    "#         \"--cpu-offload\"\n",
    "#     ])\n",
    "# \n",
    "# # Crear dir SSL\n",
    "# !mkdir -p /tmp/ssl_certs\n",
    "# \n",
    "# # Lanzar en background\n",
    "# thread = threading.Thread(target=run_server, daemon=True)\n",
    "# thread.start()\n",
    "# \n",
    "# print(\"üåê Servidor lanzado. Accede via:\")\n",
    "# print(\"   https://localhost:8998\")\n",
    "# print(\"   (O usa localtunnel/ngrok para acceso remoto)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Resultados Fase 1\n",
    "\n",
    "| M√©trica | Valor |\n",
    "|---------|-------|\n",
    "| GPU usada | T4 16GB |\n",
    "| cpu-offload | S√≠ |\n",
    "| RTF | *(llenar)* |\n",
    "| Calidad audio | *(evaluar subjetivamente)* |\n",
    "| Mejor voz femenina | *(llenar)* |\n",
    "| Mejor voz masculina | *(llenar)* |\n",
    "| Adherencia al prompt | *(evaluar)* |\n",
    "| Solo ingl√©s | ‚úÖ Confirmado |\n",
    "\n",
    "### Pr√≥ximos pasos:\n",
    "- [ ] Probar en Mac mini con personaplex-mlx (Fase 1, tarea 2)\n",
    "- [ ] Evaluar si RTF < 1.0 es alcanzable en local\n",
    "- [ ] Dise√±ar integraci√≥n con Twilio (Fase 2)"
   ]
  }
 ]
}